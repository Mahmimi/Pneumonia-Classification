{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import spaces\n",
    "import torch\n",
    "import tempfile\n",
    "from gradio_imageslider import ImageSlider\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "css = \"\"\"\n",
    "#img-display-container {\n",
    "    max-height: 100vh;\n",
    "}\n",
    "#img-display-input {\n",
    "    max-height: 80vh;\n",
    "}\n",
    "#img-display-output {\n",
    "    max-height: 80vh;\n",
    "}\n",
    "#download {\n",
    "    height: 62px;\n",
    "}\n",
    "\"\"\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "pipe = pipeline(task=\"depth-estimation\", model=\"depth-anything/Depth-Anything-V2-Large-hf\", device=DEVICE)\n",
    "\n",
    "title = \"# Depth Anything V2\"\n",
    "description = \"\"\"Official demo for **Depth Anything V2**.\n",
    "Please refer to our [paper](https://arxiv.org/abs/2406.09414), [project page](https://depth-anything-v2.github.io), and [github](https://github.com/DepthAnything/Depth-Anything-V2) for more details.\"\"\"\n",
    "\n",
    "@spaces.GPU\n",
    "def predict_depth(image):\n",
    "    return np.array(pipe(image)[\"depth\"])\n",
    "\n",
    "with gr.Blocks(css=css) as demo:\n",
    "    gr.Markdown(title)\n",
    "    gr.Markdown(description)\n",
    "    gr.Markdown(\"### Depth Prediction demo\")\n",
    "\n",
    "    with gr.Row():\n",
    "        input_image = gr.Image(label=\"Input Image\", type='pil', elem_id='img-display-input')\n",
    "        depth_image_slider = ImageSlider(label=\"Depth Map with Slider View\", elem_id='img-display-output', position=0.5)\n",
    "    submit = gr.Button(value=\"Compute Depth\")\n",
    "    gray_depth_file = gr.File(label=\"Grayscale depth map\", elem_id=\"download\",)\n",
    "    raw_file = gr.File(label=\"16-bit raw output (can be considered as disparity)\", elem_id=\"download\",)\n",
    "\n",
    "    cmap = matplotlib.colormaps.get_cmap('Spectral_r')\n",
    "\n",
    "    def on_submit(image):\n",
    "        pil = image\n",
    "        image = np.array(image)\n",
    "        original_image = image.copy()\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        depth = predict_depth(pil.convert('RGB'))\n",
    "\n",
    "        raw_depth = Image.fromarray(depth.astype('uint16'))\n",
    "        tmp_raw_depth = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n",
    "        raw_depth.save(tmp_raw_depth.name)\n",
    "\n",
    "        depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "        depth = depth.astype(np.uint8)\n",
    "        colored_depth = (cmap(depth)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "        gray_depth = Image.fromarray(depth)\n",
    "        tmp_gray_depth = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n",
    "        gray_depth.save(tmp_gray_depth.name)\n",
    "\n",
    "        return [(original_image, colored_depth), tmp_gray_depth.name, tmp_raw_depth.name]\n",
    "\n",
    "    submit.click(on_submit, inputs=[input_image], outputs=[depth_image_slider, gray_depth_file, raw_file])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.queue().launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10_torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
